{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2912fef1-b9ea-4727-9bd8-4cccd2aed5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def perceptron(inputs, weights, threshold):\n",
    "\n",
    "    assert len(inputs) == len(weights)\n",
    "\n",
    "    # multiply the inputs and weights\n",
    "    values = np.multiply(inputs,weights)\n",
    "\n",
    "    # sum the results\n",
    "    total = sum(values)\n",
    "\n",
    "    # decide if we should activate the perceptron\n",
    "    if total < threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd6f421-2f59-4cef-915a-308daf8e4fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praktikant\\anaconda3\\envs\\praktikum\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.50508630\n",
      "Iteration 2, loss = 0.24588014\n",
      "Iteration 3, loss = 0.19633463\n",
      "Iteration 4, loss = 0.16499642\n",
      "Iteration 5, loss = 0.14137676\n",
      "Iteration 6, loss = 0.12451231\n",
      "Iteration 7, loss = 0.11067141\n",
      "Iteration 8, loss = 0.09970595\n",
      "Iteration 9, loss = 0.09051628\n",
      "Iteration 10, loss = 0.08237777\n",
      "Iteration 11, loss = 0.07587572\n",
      "Iteration 12, loss = 0.06989326\n",
      "Iteration 13, loss = 0.06479280\n",
      "Iteration 14, loss = 0.05990235\n",
      "Iteration 15, loss = 0.05596584\n",
      "Iteration 16, loss = 0.05231171\n",
      "Iteration 17, loss = 0.04917291\n",
      "Iteration 18, loss = 0.04604109\n",
      "Iteration 19, loss = 0.04305221\n",
      "Iteration 20, loss = 0.04051273\n",
      "Iteration 21, loss = 0.03803553\n",
      "Iteration 22, loss = 0.03498364\n",
      "Iteration 23, loss = 0.03324595\n",
      "Iteration 24, loss = 0.03144492\n",
      "Iteration 25, loss = 0.02925737\n",
      "Iteration 26, loss = 0.02786816\n",
      "Iteration 27, loss = 0.02602835\n",
      "Iteration 28, loss = 0.02466452\n",
      "Iteration 29, loss = 0.02320235\n",
      "Iteration 30, loss = 0.02140525\n",
      "Iteration 31, loss = 0.02070122\n",
      "Iteration 32, loss = 0.01913313\n",
      "Iteration 33, loss = 0.01809438\n",
      "Iteration 34, loss = 0.01742260\n",
      "Iteration 35, loss = 0.01575047\n",
      "Iteration 36, loss = 0.01538229\n",
      "Iteration 37, loss = 0.01409820\n",
      "Iteration 38, loss = 0.01385460\n",
      "Iteration 39, loss = 0.01319592\n",
      "Iteration 40, loss = 0.01195399\n",
      "Iteration 41, loss = 0.01108379\n",
      "Iteration 42, loss = 0.01046964\n",
      "Iteration 43, loss = 0.00996964\n",
      "Iteration 44, loss = 0.00951122\n",
      "Iteration 45, loss = 0.00940722\n",
      "Iteration 46, loss = 0.00830716\n",
      "Iteration 47, loss = 0.00783090\n",
      "Iteration 48, loss = 0.00730700\n",
      "Iteration 49, loss = 0.00683145\n",
      "Iteration 50, loss = 0.00634084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praktikant\\anaconda3\\envs\\praktikum\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.9990476190476191\n",
      "Testing set score 0.9771395913701958\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as skl_data\n",
    "import sklearn.neural_network as skl_nn\n",
    "\n",
    "data, labels = skl_data.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "data = data / 255.0\n",
    "\n",
    "\n",
    "mlp = skl_nn.MLPClassifier(hidden_layer_sizes=(50,), max_iter=50, verbose=1, random_state=1)\n",
    "\n",
    "data_train = data[0:63000]\n",
    "labels_train = labels[0:63000]\n",
    "\n",
    "data_test = data[63001:]\n",
    "labels_test = labels[63001:]\n",
    "\n",
    "mlp.fit(data_train, labels_train)\n",
    "print(\"Training set score\", mlp.score(data_train, labels_train))\n",
    "print(\"Testing set score\", mlp.score(data_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494f6c9-a46e-4e64-9982-37f37a10cffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
